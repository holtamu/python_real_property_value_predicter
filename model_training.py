## 3. í…ì„œí”Œë¡œ ëª¨ë¸ë§
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 1. ë°ì´í„° ë¡œë“œ
try:
    df = pd.read_csv("geumcheon_apt_2024_cleaned.csv")
    print("âœ… ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
except FileNotFoundError:
    print("âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. main.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    exit()

# 2. [ìˆ˜ì •] íŠ¹ì§•(X)ê³¼ ì •ë‹µ(y) ë¶„ë¦¬
# ë²•ì •ë™(ê¸€ì)ì„ 0ê³¼ 1ë¡œ ë³€í™˜í•˜ëŠ” ì›-í•« ì¸ì½”ë”©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
df_encoded = pd.get_dummies(df, columns=['ë²•ì •ë™'])

# ì…ë ¥ ë°ì´í„°: ì „ìš©ë©´ì , ì•„íŒŒíŠ¸ë‚˜ì´ + ë²•ì •ë™_ê°€ì‚°ë™, ë²•ì •ë™_ë…ì‚°ë™, ë²•ì •ë™_ì‹œí¥ë™ ë“±
# ì¶œë ¥ ë°ì´í„°: ê±°ë˜ê¸ˆì•¡
# filterë¥¼ ì¨ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ Xë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
X = df_encoded.filter(regex='ì „ìš©ë©´ì |ì•„íŒŒíŠ¸ë‚˜ì´|ë²•ì •ë™_').values
y = df_encoded['ê±°ë˜ê¸ˆì•¡'].values

# 3. ë°ì´í„°ì…‹ ë¶„í•  (í•™ìŠµìš© 80%, í…ŒìŠ¤íŠ¸ìš© 20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (í‘œì¤€í™”)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 5. [ìˆ˜ì •] ì¸ê³µì‹ ê²½ë§ ëª¨ë¸ ì„¤ê³„
# input_shapeë¥¼ ê³ ì •ëœ (2,)ê°€ ì•„ë‹ˆë¼ Xì˜ ì»¬ëŸ¼ ê°œìˆ˜ì— ë§ì¶° ìë™ìœ¼ë¡œ ì„¤ì •í•˜ê²Œ ë°”ê¿¨ìŠµë‹ˆë‹¤.
model = tf.keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)), 
    layers.Dense(32, activation='relu'),
    layers.Dense(16, activation='relu'),
    layers.Dense(1)
])

# 6. ëª¨ë¸ ì„¤ì • (ì»´íŒŒì¼)
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# 7. ì¸ê³µì§€ëŠ¥ í•™ìŠµ ì‹œì‘
print("\nğŸ¤– ë²•ì •ë™ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì¸ê³µì§€ëŠ¥ í•™ìŠµ ì¤‘...")
history = model.fit(
    X_train_scaled, y_train, 
    epochs=100, 
    batch_size=32, 
    validation_split=0.2,
    verbose=0 
)
print("âœ¨ í•™ìŠµ ì™„ë£Œ!")

# 8. í•™ìŠµ ê²°ê³¼ ì‹œê°í™” (Loss ê·¸ë˜í”„)
# --- ìœˆë„ìš° í•œê¸€ í°íŠ¸ ì„¤ì • ì¶”ê°€ ---
plt.rc('font', family='Malgun Gothic') # ë§‘ì€ ê³ ë”• ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
# ---------------------------------
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='í•™ìŠµ ì†ì‹¤ (Train Loss)')
plt.plot(history.history['val_loss'], label='ê²€ì¦ ì†ì‹¤ (Val Loss)')
plt.title('ëª¨ë¸ í•™ìŠµ ê³¼ì • (Loss)')
plt.xlabel('ë°˜ë³µ íšŸìˆ˜ (Epochs)')
plt.ylabel('ì†ì‹¤ ê°’ (MSE)')
plt.legend()
plt.show()

# 9. ëª¨ë¸ í‰ê°€
loss, mae = model.evaluate(X_test_scaled, y_test, verbose=0)
print(f"\nğŸ“Š ëª¨ë¸ í‰ê°€ ê²°ê³¼ (MAE): í‰ê·  ì•½ {round(mae, 2)}ë§Œì› ì •ë„ì˜ ì˜¤ì°¨ê°€ ë°œìƒí•©ë‹ˆë‹¤.")


# 10. ì‚¬ìš©ì ì…ë ¥í˜• ì‹¤ì œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸

print("\n" + "="*50)
print("ğŸ  ê¸ˆì²œêµ¬ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ ì‹œë®¬ë ˆì´í„°")
print("="*50)

# --- 1. ì „ìš©ë©´ì  ì„ íƒ ---
unique_areas = sorted(df['ì „ìš©ë©´ì '].unique())
print("\n[1] ì „ìš©ë©´ì ì„ ì„ íƒí•˜ì„¸ìš” (ã¡):")
for i, area in enumerate(unique_areas, 1):
    print(f"{i}. {area}ã¡")
area_choice = int(input("ë²ˆí˜¸ ì…ë ¥ >> ")) - 1
input_area = unique_areas[area_choice]

# --- 2. ì•„íŒŒíŠ¸ ë‚˜ì´ ì„ íƒ ---
unique_ages = sorted(df['ì•„íŒŒíŠ¸ë‚˜ì´'].unique())
print("\n[2] ì•„íŒŒíŠ¸ ë‚˜ì´(ê±´ì¶•ë…„ë„ ê¸°ì¤€)ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
for i, age in enumerate(unique_ages, 1):
    print(f"{i}. {age}ë…„")
age_choice = int(input("ë²ˆí˜¸ ì…ë ¥ >> ")) - 1
input_age = unique_ages[age_choice]

# --- 3. ë²•ì •ë™ ì„ íƒ ---
unique_dongs = sorted(df['ë²•ì •ë™'].unique())
print("\n[3] ë²•ì •ë™(ë™ë„¤)ì„ ì„ íƒí•˜ì„¸ìš”:")
for i, dong in enumerate(unique_dongs, 1):
    print(f"{i}. {dong}")
dong_choice = int(input("ë²ˆí˜¸ ì…ë ¥ >> ")) - 1
input_dong = unique_dongs[dong_choice]

# --- 4. ë°ì´í„° ë³€í™˜ ë° ì˜ˆì¸¡ ---
# ì›-í•« ì¸ì½”ë”©ëœ ì»¬ëŸ¼ ìˆœì„œì— ë§ì¶°ì„œ 0ê³¼ 1ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
test_columns = df_encoded.filter(regex='ì „ìš©ë©´ì |ì•„íŒŒíŠ¸ë‚˜ì´|ë²•ì •ë™_').columns
dong_features = [1 if f"ë²•ì •ë™_{input_dong}" == col else 0 for col in test_columns if "ë²•ì •ë™_" in col]

# [ë©´ì , ë‚˜ì´, ê°€ì‚°ë™(0), ë…ì‚°ë™(0), ì‹œí¥ë™(1) ...] í˜•íƒœë¡œ ì¡°í•©
sample_data = np.array([[input_area, input_age] + dong_features])
sample_scaled = scaler.transform(sample_data)
prediction = model.predict(sample_scaled, verbose=0)

# --- 5. ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---
print("\n" + "ê²°ê³¼ ë¶„ì„ ì¤‘..." + "."*10)
print(f"\nâœ… ì„ íƒí•˜ì‹  ì¡°ê±´:")
print(f"ğŸ“ ìœ„ì¹˜: {input_dong} | ë©´ì : {input_area}ã¡ | ë‚˜ì´: {input_age}ë…„")
print("-" * 50)
print(f"ğŸ’° ì¸ê³µì§€ëŠ¥ ì˜ˆì¸¡ ê±°ë˜ê°€: ì•½ {round(prediction[0][0], -1):,} ë§Œì›")
print("="*50)

# 11. Gemini ì—°ë™í•˜ê¸°
# gemini_analysis.pyì—ì„œ í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
from gemini_analysis import get_gemini_report

# ë¶ˆëŸ¬ì˜¨ í•¨ìˆ˜ ì‹¤í–‰
report = get_gemini_report(input_dong, input_area, input_age, prediction.item())

# 3. ê²°ê³¼ ì¶œë ¥
print("\n" + "="*50)
print("ğŸ  Gemini ì „ë¬¸ê°€ ë¶„ì„ ë¦¬í¬íŠ¸")
print("-" * 50)
print(report)
print("="*50)